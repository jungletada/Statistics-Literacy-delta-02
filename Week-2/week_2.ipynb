{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2-1\n",
    "### Approximation method 1\n",
    " When the random variable $X$ follows $\\mathcal{B}(n,p)$,  $\\hat{p}^∗ = \\frac{X+0.5}{n+1}$ follows $\\mathcal{N}(p, \\frac{p(1-p)}{n})$\n",
    " in a similar way.\n",
    "### Approximation method 2\n",
    "Let $L$ be a function $L(x)=\\rm{ln}\\frac{x}{1-x}$. The transformation of numbers by thisfunction is called the **logit transformation**.  \n",
    "When the random variable $X$ follows $\\mathcal{B}(n,p)$,  $L(\\mathcal{B}(n,p))$ follows approximately $\\mathcal{N}(L(p), \\frac{1}{np(1-p)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_1(n, p0, X):\n",
    "    p_hat = (X + 0.5) / (n + 1)\n",
    "    U0 = (p_hat - p0) / np.sqrt(p0 * (1 - p0) / n)\n",
    "    return U0\n",
    "\n",
    "\n",
    "def logit_transform(p):\n",
    "    assert 0 < p < 1\n",
    "    return np.log(p / (1-p))\n",
    "\n",
    "\n",
    "def approx_2(n, p0, X):\n",
    "    p_hat = (X + 0.5) / (n + 1)\n",
    "    Lp_hat = logit_transform(p_hat)\n",
    "    Lp_0 = logit_transform(p0)\n",
    "    U0 = (Lp_hat - Lp_0) * np.sqrt(n * p0 * (1 - p0))\n",
    "    return U0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation method 1 = -0.932, Approximation method 2 = -1.023\n"
     ]
    }
   ],
   "source": [
    "# n, X, p0 = 20, 11, 1/3\n",
    "# alpha = 0.01\n",
    "\n",
    "n, X, p0 = 500, 20, 0.05\n",
    "alpha = 0.05\n",
    "\n",
    "U_01 = approx_1(n, p0, X)\n",
    "U_02 = approx_2(n, p0, X)\n",
    "print(\"Approximation method 1 = {:.3f}, Approximation method 2 = {:.3f}\".format(U_01, U_02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of the parameters of binomial distribution\n",
    "Estimate the parameter (population) $p$ of the binomial distribution.  \n",
    "There are two types of parameter estimation: point estimation and interval estimation.   \n",
    "For point estimation, $\\hat{p}=\\frac{X}{n}$ or $\\hat{p}^∗=\\frac{X+0.5}{n+1}$ is used as the estimator. \n",
    "$$\n",
    "\\rm{Pr}\\left\\{z(\\frac{\\alpha}{2})≤U_0≤z(1−\\frac{\\alpha}{2})\\right\\}\\approx 1−\\alpha\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejection region statistic=1.960\n",
      "Method 1 Interval=(0.024, 0.058)\n",
      "Method 2 Interval=(0.027, 0.062)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the rejection region\n",
    "n_statistic = stats.norm.ppf(1 - alpha/2)\n",
    "print(\"rejection region statistic={:.3f}\".format(n_statistic))\n",
    "alpha_half = alpha / 2\n",
    "n_statistic_left = stats.norm.ppf(alpha_half)\n",
    "n_statistic_right = stats.norm.ppf(1 - alpha_half)\n",
    "lambda_hs = (X + 0.5) / (n + 1)\n",
    "\n",
    "# Method 1\n",
    "var = np.sqrt(lambda_hs * (1 - lambda_hs) / n)\n",
    "lower_interval1 = n_statistic_left * var + lambda_hs\n",
    "upper_interval1 = n_statistic_right * var + lambda_hs\n",
    "print(\"Method 1 Interval=({:.3f}, {:.3f})\".format(lower_interval1, upper_interval1))\n",
    "\n",
    "# Method 2\n",
    "Lp_hs = logit_transform(lambda_hs)\n",
    "var = 1 / np.sqrt(n * lambda_hs * (1 - lambda_hs))\n",
    "lower_interval2 = 1 / (1 + np.exp(-(n_statistic_left * var + Lp_hs)))\n",
    "upper_interval2 = 1 / (1 + np.exp(-(n_statistic_right * var + Lp_hs)))\n",
    "\n",
    "print(\"Method 2 Interval=({:.3f}, {:.3f})\".format(lower_interval2, upper_interval2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2-2\n",
    "- **Approximation method 1**  \n",
    " When the random variable $W$ follows $Po(\\lambda)$, $\\hat{p}^∗ = \\frac{X+0.5}{n+1}$ follows $\\mathcal{N}(p, \\frac{p(1-p)}{n})$\n",
    " in a similar way.  \n",
    "- **Approximation method 2**  \n",
    "Let $L$ be a function $L(x)=\\rm{ln}\\frac{x}{1-x}$. The transformation of numbers by thisfunction is called the **logit transformation**.  \n",
    "When the random variable $X$ follows $\\mathcal{B}(n,p)$,  $L(\\mathcal{B}(n,p))$ follows approximately $\\mathcal{N}(L(p), \\frac{1}{np(1-p)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def po_approx_1(n, W, lambda_0):\n",
    "    lambda_hs = (W + 0.5) / n\n",
    "    U0 = (lambda_hs - lambda_0) / np.sqrt(lambda_0 / n)\n",
    "    return U0\n",
    "\n",
    "\n",
    "def po_approx_2(n, W, lambda_0):\n",
    "    lambda_hs = (W + 0.5) / n\n",
    "    U0 = (np.log(lambda_hs) - np.log(lambda_0)) * np.sqrt(n * lambda_0)\n",
    "    return U0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximation method 1 = 2.166, Approximation method 2 = 1.960\n"
     ]
    }
   ],
   "source": [
    "# exercise 2-2\n",
    "n, W, lambda_0 = 9986, 121, 0.01\n",
    "alpha = 0.05\n",
    "\n",
    "U_01 = po_approx_1(n, W, lambda_0)\n",
    "U_02 = po_approx_2(n, W, lambda_0)\n",
    "print(\"Approximation method 1 = {:.3f}, Approximation method 2 = {:.3f}\".format(U_01, U_02))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter estimation of Poisson distribution\n",
    "There are two types of parameter estimation: point estimation and interval estimation.  \n",
    "For point estimation, $\\hat{λ} = W$ or $\\hat{λ}^∗ = \\frac{W+0.5}{n}$ is used as estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejection region statistic=1.645\n",
      "Method 1 Interval=(0.010, 0.014)\n",
      "Method 2 Interval=(0.010, 0.015)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the rejection region\n",
    "n_statistic = stats.norm.ppf(1 - alpha)\n",
    "print(\"rejection region statistic={:.3f}\".format(n_statistic))\n",
    "alpha_half = alpha / 2\n",
    "\n",
    "n_statistic_left = stats.norm.ppf(alpha_half)\n",
    "n_statistic_right = stats.norm.ppf(1 - alpha_half)\n",
    "lambda_hs = (W + 0.5) / n\n",
    "\n",
    "# Method 1\n",
    "var = np.sqrt(lambda_hs / n)\n",
    "lower_interval1 = n_statistic_left * var + lambda_hs\n",
    "upper_interval1 = n_statistic_right * var + lambda_hs\n",
    "print(\"Method 1 Interval=({:.3f}, {:.3f})\".format(lower_interval1, upper_interval1))\n",
    "\n",
    "# Method 2\n",
    "ln_lambda = np.log(lambda_hs)\n",
    "var = 1 / np.sqrt(n * lambda_hs)\n",
    "lower_interval2 = np.exp(n_statistic_left * var + ln_lambda)\n",
    "upper_interval2 = np.exp(n_statistic_right * var + ln_lambda)\n",
    "\n",
    "print(\"Method 2 Interval=({:.3f}, {:.3f})\".format(lower_interval2, upper_interval2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2-3\n",
    "Test and Estimate on the Population Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_t0(R, n):\n",
    "    return (R * np.sqrt(n - 2)) / np.sqrt(1 - R * R)\n",
    "\n",
    "def approx_z(R):\n",
    "    return 0.5 * np.log((1 + R) / (1 - R))\n",
    "\n",
    "def read_from_excel(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    columns_data = {col: df[col].values for col in df.columns}\n",
    "    A = columns_data[df.columns[1]]\n",
    "    B = columns_data[df.columns[2]]\n",
    "    A = A[~np.isnan(A)]\n",
    "    B = B[~np.isnan(B)]\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Correlation Coefficient R = 0.795, number of samples n = 50\n",
      "t-stat approximation = 9.081\n",
      "rejection region statistic = 1.677\n"
     ]
    }
   ],
   "source": [
    "A, B = read_from_excel('mini-exam2-3.xlsx')\n",
    "correlation_matrix = np.corrcoef(A, B)\n",
    "R, n = correlation_matrix[0, 1], len(A)\n",
    "\n",
    "df = n - 2\n",
    "t0 = approx_t0(R, n)\n",
    "\n",
    "alpha = 0.05\n",
    "alpha_half = alpha / 2\n",
    "t_statistic = stats.t.ppf(1 - alpha, df)\n",
    "\n",
    "print(\"Sample Correlation Coefficient R = {:.3f}, number of samples n = {}\".format(R, n))\n",
    "print(\"t-stat approximation = {:.3f}\".format(t0))\n",
    "print(\"rejection region statistic = {:.3f}\".format(t_statistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of Population Correlation Coefficient\n",
    "Estimate population correlation coefficient $ρ$.  \n",
    "There are two types of parameter estimation: point estimation and interval estimation.   \n",
    "- For point estimation, $\\hat{p}=R$. \n",
    "- For interval estimation, we use the fact that $Z=\\frac{1}{2}{\\rm ln}\\frac{1+R}{1-R}$ approximately follows $\\mathcal{N}(\\frac{1}{2}{\\rm ln}\\frac{1+ρ}{1-ρ}, \\frac{1}{n-3})$ when $\\rho \\neq 0$.   \n",
    "$$\n",
    "{\\rm Pr}\\left\\{z(\\frac{\\alpha}{2})≤\\frac{Z-\\frac{1}{2}{\\rm ln}\\frac{1+ρ}{1-ρ}}{\\sqrt{\\frac{1}{n-3}}}≤z(1−\\frac{\\alpha}{2})\\right\\}\\approx 1−\\alpha\n",
    "$$\n",
    "When $\\zeta=\\frac{1}{2}{\\rm ln}\\frac{1+ρ}{1-ρ}$ is used, \n",
    "$$\n",
    "{\\rm Pr}\\left\\{Z - z(1−\\frac{\\alpha}{2})\\sqrt{\\frac{1}{n-3}} \\leq \n",
    "\\zeta \\leq Z-z(\\frac{\\alpha}{2})\\sqrt{\\frac{1}{n-3}}\\right\\}\\approx 1−\\alpha\n",
    "$$\n",
    "Then we get   \n",
    " $$\\rho=\\frac{e^{2\\zeta-1}}{e^{2\\zeta+1}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval for ρ is (0.664, 0.879)\n"
     ]
    }
   ],
   "source": [
    "Z = 0.5 * np.log((1 + R) / (1 - R))\n",
    "n_statistic_left = stats.norm.ppf(alpha_half)\n",
    "n_statistic_right = stats.norm.ppf(1 - alpha_half)\n",
    "\n",
    "def transform_to_coeff(zeta):\n",
    "    return (np.exp(2*zeta) - 1) / (np.exp(2*zeta) + 1)\n",
    "\n",
    "zeta1 = Z - n_statistic_right / np.sqrt(n - 3)\n",
    "zeta2 = Z - n_statistic_left / np.sqrt(n - 3)\n",
    "\n",
    "rho1 = transform_to_coeff(zeta1)\n",
    "rho2 = transform_to_coeff(zeta2)\n",
    "print(\"confidence interval for ρ is ({:.3f}, {:.3f})\".format(rho1, rho2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine A (grade) = {1: 55, 2: 40, 3: 5}\n",
      "Machine B (grade) = {1: 68, 3: 22, 2: 10}\n",
      "[[55 40  5]\n",
      " [68 10 22]]\n",
      "[[61.5 25.  13.5]]\n",
      "X^2 test statistic = 30.078, degree of freedom = 2\n",
      "rejection region = 5.991\n"
     ]
    }
   ],
   "source": [
    "# Video 2-4\n",
    "df = pd.read_excel('2-4_Test on Contingency Table.xlsx', index_col=0)\n",
    "\n",
    "expected_table, table = {}, []\n",
    "for col in df.columns:\n",
    "    value_counts = df[col].value_counts().to_dict()\n",
    "    expected_table[col] = value_counts\n",
    "    print(f\"{col} = {value_counts}\")\n",
    "\n",
    "A, B = expected_table[df.columns[0]], expected_table[df.columns[1]]\n",
    "keys = sorted(A.keys())  # 获取所有键并排序\n",
    "A_values = [A[k] for k in keys]  # 按照排序的键顺序提取A的值\n",
    "B_values = [B[k] for k in keys]  # 按照排序的键顺序提取B的值\n",
    "\n",
    "table = [A_values, B_values]\n",
    "table = np.array(table)\n",
    "print(table)\n",
    "\n",
    "sum_prod = np.sum(table, axis=1)\n",
    "sum_grade = np.sum(table, axis=0)\n",
    "\n",
    "expected_tab = np.mean(table, axis=0, keepdims=True)\n",
    "print(expected_tab)\n",
    "\n",
    "diff = (table - expected_tab)**2 / expected_tab\n",
    "chi = np.sum(diff)\n",
    "alpha = 0.05\n",
    "df = (table.shape[0] - 1) * (table.shape[1] - 1)\n",
    "chi_inv = stats.chi2.ppf(1 - alpha, df)\n",
    "print(\"X^2 test statistic = {:.3f}, degree of freedom = {}\".format(chi, df))\n",
    "print(\"rejection region = {:.3f}\".format(chi_inv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected_table:\n",
      "[[77 37 35]\n",
      " [77 37 35]\n",
      " [77 37 35]]\n",
      "sum rows = [150 150 150]\n",
      "sum columns = [231 113 106]\n",
      "X^2 test statistic = 2.381\n",
      "degree of freedom = 1\n",
      "rejection region = 3.841\n"
     ]
    }
   ],
   "source": [
    "# Mini-Exam 2-4\n",
    "contingency_table = np.array([[66, 38, 46], [72, 36, 42], [93, 39, 18]])\n",
    "row_sums = np.sum(contingency_table, axis=1)\n",
    "col_sums = np.sum(contingency_table, axis=0)\n",
    "total_sums = np.sum(contingency_table)\n",
    "expected_table = np.empty_like(contingency_table)\n",
    "\n",
    "# 计算新数组中的每个元素\n",
    "for i in range(expected_table.shape[0]):\n",
    "    for j in range(expected_table.shape[1]):\n",
    "        expected_table[i, j] = row_sums[i] * col_sums[j] / total_sums\n",
    "\n",
    "diff = (table - expected_tab) **2 / expected_tab\n",
    "chi = np.sum(diff)\n",
    "alpha = 0.05\n",
    "df = (table.shape[0] - 1) * (table.shape[1] - 1)\n",
    "chi_inv = stats.chi2.ppf(1 - alpha, df)\n",
    "\n",
    "print(\"expected_table:\")\n",
    "print(expected_table)\n",
    "print(\"sum rows = {}\".format(row_sums))\n",
    "print(\"sum columns = {}\".format(col_sums))\n",
    "print(\"X^2 test statistic = {:.3f}\\ndegree of freedom = {}\".format(chi, df))\n",
    "print(\"rejection region = {:.3f}\".format(chi_inv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
