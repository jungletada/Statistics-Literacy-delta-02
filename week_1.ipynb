{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Literacy delta 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_from_excel(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    columns_data = {col: df[col].values for col in df.columns}\n",
    "    A = columns_data[df.columns[0]]\n",
    "    B = columns_data[df.columns[1]]\n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degrees of freedom=18\n",
      "t-statistic=2.256\n",
      "Two-tailed test p-value = 0.037\n",
      "Rejection region: t_0 < -2.101 or t_0 > 2.101\n",
      "Confidence limit=[0.065, 1.815]\n"
     ]
    }
   ],
   "source": [
    "# Video 1-1\n",
    "# A = np.array([0.5, 0.4, 0.5,0.0, 0.6, 0.5, 0.5, 0.6, 0.4, 0.7])\n",
    "# B = np.array([1.3, 1.3, 0.7, 0.8, 1.4, 0.1, 0.4, 1.3, 1.7, 1.0])\n",
    "\n",
    "# exercise 1-1\n",
    "# A = np.array([56,67,55,60,52,58,49,54,53,50])\n",
    "# B = np.array([68,58,52,48,40,60,43,57,61,50])\n",
    "\n",
    "# exam 1-1\n",
    "A = np.array([13,11.1,12.5,10.1,10.7,13.2,11.5,10.9,13.2,12.8])\n",
    "B = np.array([12,10,10.8,10.4,11.1,10.7,11.5,11.2,11.5,10.4])\n",
    "\n",
    "# Sample sizes\n",
    "n1 = len(A)\n",
    "n2 = len(B)\n",
    "# Means\n",
    "mean1 = np.mean(A)\n",
    "mean2 = np.mean(B)\n",
    "# Variances\n",
    "var1 = np.var(A, ddof=1)  # Use ddof=1 for sample variance\n",
    "var2 = np.var(B, ddof=1)\n",
    "# Pooled variance\n",
    "pooled_variance = ((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2)\n",
    "# Standard error\n",
    "standard_error = np.sqrt(pooled_variance * (1/n1 + 1/n2))\n",
    "# t-statistic\n",
    "t_statistic = (mean1 - mean2) / standard_error\n",
    "mean_diff = mean1 - mean2\n",
    "\n",
    "# Degrees of freedom\n",
    "degrees_of_freedom = n1 + n2 - 2\n",
    "\n",
    "# p-value\n",
    "p_value = stats.t.sf(np.abs(t_statistic), df=degrees_of_freedom) * 2  # Two-tailed test\n",
    "\n",
    "print(\"Degrees of freedom={}\\nt-statistic={:.3f}\\nTwo-tailed test p-value = {:.3f}\".format(\n",
    "    degrees_of_freedom, t_statistic, p_value))\n",
    "\n",
    "# Significance level for a two-tailed test (e.g., 0.02 significance level)\n",
    "alpha = 0.05\n",
    "# For a two-tailed test, divide the alpha by 2\n",
    "alpha_half = alpha / 2\n",
    "# Calculate the t critical value\n",
    "t_critical = stats.t.ppf(alpha_half, degrees_of_freedom)\n",
    "# Since it's two-tailed, we need both the positive and negative critical values\n",
    "negative_t_critical = t_critical\n",
    "positive_t_critical = -t_critical\n",
    "\n",
    "lower_conf = mean_diff + negative_t_critical * standard_error\n",
    "upper_conf = mean_diff + positive_t_critical * standard_error\n",
    "\n",
    "print(\"Rejection region: t_0 < {:.3f} or t_0 > {:.3f}\".format(negative_t_critical, positive_t_critical))\n",
    "print(\"Confidence limit=[{:.3f}, {:.3f}]\".format(lower_conf, upper_conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video 1-2\n",
    "\n",
    "\n",
    "# # exercise 1-2\n",
    "# A, B = read_from_excel('practice1-2.xlsx')\n",
    "\n",
    "# exam 1-2\n",
    "A, B = read_from_excel('mini-exam1-2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean(A)=35.750, Mean(B)=34.250\n",
      "Unbiased variance estimators \\sigma(A)=6.022727, \\sigma(B)=2.750000, v_1/v_2=2.190\n",
      "Rejection region: 0.288, 3.474\n",
      "confidence interval for 21/22=[0.630, 7.608]\n"
     ]
    }
   ],
   "source": [
    "# Sample sizes\n",
    "n1 = len(A)\n",
    "n2 = len(B)\n",
    "# Means\n",
    "mean1 = np.mean(A)\n",
    "mean2 = np.mean(B)\n",
    "# Variances. Use ddof=1 for sample variance\n",
    "var1 = np.var(A, ddof=1) \n",
    "var2 = np.var(B, ddof=1)\n",
    "varience_ratio = var1 / var2\n",
    "print(\"Mean(A)={:.3f}, Mean(B)={:.3f}\".format(mean1, mean2))\n",
    "print(\"Unbiased variance estimators \\sigma(A)={:.6f}, \\sigma(B)={:.6f}, v_1/v_2={:.3f}\".format(var1, var2, varience_ratio))\n",
    "\n",
    "# Significance level for a two-tailed test (e.g., 0.02 significance level)\n",
    "alpha = 0.05\n",
    "# For a two-tailed test, divide the alpha by 2\n",
    "alpha_half = alpha / 2\n",
    "# Calculate the F-distribution critical value\n",
    "f_critical_low = stats.f.ppf(alpha_half, dfn=n1-1, dfd=n2-1)\n",
    "f_critical_high = stats.f.ppf(1 - alpha_half, dfn=n1-1, dfd=n2-1)\n",
    "\n",
    "lower_conf = varience_ratio / f_critical_high\n",
    "upper_conf = varience_ratio / f_critical_low\n",
    "print(\"Rejection region: {:.3f}, {:.3f}\".format(f_critical_low, f_critical_high))\n",
    "print(\"confidence interval for 21/22=[{:.3f}, {:.3f}]\".format(lower_conf, upper_conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
